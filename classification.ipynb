{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fbe78f-4109-411a-9ad0-42740c64f59e",
   "metadata": {},
   "source": [
    "# Python: Initial data prep section.  Read, clean and create sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5b622-8340-4fd9-9ea6-9924cddff3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv('BTC-USD.csv')\n",
    "print(dataset.info())\n",
    "print(dataset.keys())\n",
    "print(dataset.describe())\n",
    "print(dataset.hist())\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set,test_set = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e546354-a610-4c84-8edf-cabf93b58701",
   "metadata": {},
   "source": [
    "#### description:\n",
    "According to my dataset, there is no null value so, I do not need to clear the data set. and except the \"DATE\" there is no value which is not number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e834619-265b-4f9e-8408-f644210a9375",
   "metadata": {},
   "source": [
    "## Markdown: Pick an initial set of features for X and the target feature y.  Explain why you made these choices.  (Note, A target that is continuous can be made discrete by creating buckets that hold a range of values. For example: If you have a feature time_of_day that ranges from 0 to 23:59, you can create 24 buckets for each of the hour intervals, 0 to 0:59, 1 to 1:59, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918ae4a-4138-425d-a6b1-bacf3e490cc8",
   "metadata": {},
   "source": [
    "My target variable, y, will represent the price. However, when looking at my dataset, I see various features that indicate prices, such as 'Open', 'High', 'Low', 'Close', 'Adj Close', and 'fluctuation rate'. Since I want to explain price increases with my data and model, 'High' will be my target feature. Additionally, 'Volume' will be my predictor variable, x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b4234-9c0b-4853-bbda-8d8f4552a659",
   "metadata": {},
   "source": [
    "## Python: Do a decision tree on  X and y.  Compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a87e6-565c-4323-ab18-265114977cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X=train_set[['Volume']]\n",
    "y=train_set['High']\n",
    "X_test=test_set[['Volume']]\n",
    "y_test=test_set['High']\n",
    "tree=DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X,y)\n",
    "y_train_pred=tree.predict(X)\n",
    "y_test_pred=tree.predict(X_test)\n",
    "r2=tree.score(X,y)\n",
    "mse=mean_squared_error(y,y_train_pred)\n",
    "r2_test=tree.score(X_test,y_test)\n",
    "mse_test=mean_squared_error(y_test,y_test_pred)\n",
    "print(r2,mse,r2_test,mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afea8b-5c07-43de-971f-dd02cc887ea7",
   "metadata": {},
   "source": [
    "## Markdown: Comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15402ed-fc0f-45db-90d6-48ecbd9bd484",
   "metadata": {},
   "source": [
    "The R-squared value for the training data is 0.91, indicating that the model explains a significant portion of the variance in the training data. The MSE for the training data is 28,237,608.85, suggesting that the difference between the predicted and actual values is not substantial.\n",
    "<br>\n",
    "However, the R-squared value for the test data is 0.22, showing that the model's ability to explain the variance in the test data is considerably low. The MSE for the test data is 179,664,678.10, indicating a significant difference between the predicted and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95372c55-d101-4239-aa69-5555ab46836a",
   "metadata": {},
   "source": [
    "## Python: See if you can do better using SVM or some other multi-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce163ee5-dd5c-4dea-b694-de3ea8d8abfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "svm = SVR(kernel=\"linear\")\n",
    "svm.fit(X, y)\n",
    "y_pred_svm = svm.predict(X)\n",
    "y_test_pred_svm = svm.predict(X_test)\n",
    "r2_train_svm = svm.score(X, y_pred_svm)\n",
    "mse_train_svm = mean_squared_error(y, y_pred_svm)\n",
    "r2_test_svm = svm.score(X_test, y_test_pred_svm)\n",
    "mse_test_svm = mean_squared_error(y_test, y_test_pred_svm)\n",
    "print(r2_train_svm,mse_train_svm,r2_test_svm,mse_test_svm)\n",
    "print(svm.support_) \n",
    "print(svm.support_vectors_) \n",
    "print(svm.n_support_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b57c0-7096-4b15-86d3-130f6b824f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y)\n",
    "plt.plot(y_pred_svm, label='Predicted')\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f47fa9-67d7-47c0-8d32-8a04919a361d",
   "metadata": {},
   "source": [
    "### result:\n",
    "The R2 value of 1 obtained for both the training and test sets indicates that the model can perfectly explain the variability of the data. However, the MSE values of 367634501.22843015 for the training set and 255988430.89353034 for the test set imply that the model has significant prediction errors when predicting the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087f734-2ca6-4796-8fca-e924ee022206",
   "metadata": {},
   "source": [
    "## Python: Do a final evaluation with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45665c6f-27b1-4ddc-bd30-0cb1f559b5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The R score and MSE of test set from decision tree: \",r2_test,mse_test)\n",
    "print(\"The R score and MSE of test set from SVM: \",r2_test_svm,mse_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5530c-28df-4b19-a1d1-921385642738",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "* Both the decision tree and SVM models achieved a perfect R-score of 1.0 on the test set. This indicates that these models perfectly explain the variance of the target variable. However, both models have relatively high mean squared error (MSE) values. The decision tree has an MSE of approximately 179,664,678, and the SVM has an MSE of approximately 255,988,431.<br>\n",
    "* While the model has high explanatory power (indicated by the significantly high R-score), it may not have high prediction accuracy for individual instances (high MSE values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0c8ab-79ac-4431-8c3c-7b1524df08b3",
   "metadata": {},
   "source": [
    "## Markdown: Look at the parameters you found and discuss what you have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ffbcaf-ecb3-44fc-aa04-6b1f769f032b",
   "metadata": {},
   "source": [
    "* I used Volume and High as parameters because I wanted to explain the volatility of High using Volume. \n",
    "* In decision tree regression, I obtained a high r value of 1.0, indicating good explanatory power, but a very high MSE value of 179,664,678. This indicates that although the model explains well, significant errors occur when applying predictions. Similarly, I observed the same phenomenon in SVR. Despite obtaining a high r value of 1.0, the MSE was approximately 255,988,431, indicating even higher errors. This suggests that the SVR model has larger errors in predictions compared to the DT model.\n",
    "* Through this, I learned that while an r score of 1.0 is very positive, obtaining a high MSE indicates that the model may have significant errors in predictions. This could imply that although the model explains the training data well, it may not generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722846ca-be64-476a-be37-de0c960d68dd",
   "metadata": {},
   "source": [
    "# Project Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06818c-289b-44b6-aa9e-189b0dc9bfe5",
   "metadata": {},
   "source": [
    "## Try clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1cac7-ed84-42f4-80d7-df7dfd25250d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "t = dataset.drop(['Date', 'Open'], axis=1)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(t)\n",
    "clusters = kmeans.predict(t)\n",
    "plt.scatter(t['High'],t['Volume'], c=clusters, cmap='viridis')#cmap='viridis' enables to change the colors depend on the value.\n",
    "plt.xlabel('High')\n",
    "plt.ylabel('Volume')\n",
    "plt.savefig('kmean_clust.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cc228-77a0-4e26-aa61-67f01970d1b3",
   "metadata": {},
   "source": [
    "* when I change the x and y, I can easily see the cluster in the above plot. I could find the pattern below the Volume 4 that the maximum price is different depending on the volume size and also the minimum price is depending on the volume. if the volume is small the minimum price is low, and if the volume is bigger, then the maximum volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37068db2-8534-43a0-a782-494edf1ce412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to distinguish if the volume is higher than the mean or not.\n",
    "dataset['volume_h_r_mean'] = (dataset['Volume'] > dataset['Volume'].mean()).astype(int)\n",
    "dataset['fluctuation_P_N'] = (dataset['fluctuation rate'] >0).astype(int)\n",
    "d = dataset[['volume_h_r_mean', 'fluctuation_P_N']]\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "dataset['cluster'] = kmeans.fit_predict(d)\n",
    "print(dataset.head(10))\n",
    "print(dataset.tail(10))\n",
    "plt.scatter(dataset['Volume'], dataset['fluctuation rate'], c=dataset['cluster'], cmap='viridis')\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Fluctuation Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4df376-9779-4a08-ba6a-02820a1f5600",
   "metadata": {},
   "source": [
    "## Do dimensional analysis\n",
    "- For the both of the cluster, I used kmeans algorithm. for the first, I used volume as x and price as y to find some of the patter between them. I could find that the low points are getting increased, however, I cannot find any patter at the upper side. \n",
    "- for the scond cluster I tried to classify both variables volume and fluctuation rate as if the volume is above the mean of volumes or not, if the fluctuation is positive or negative. with this dimensionals I cannot find any pattern. the dots are evenly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0258f-1335-4701-a4ff-5efb3c026455",
   "metadata": {},
   "source": [
    "## Important notice.\n",
    "* My data involves using Bitcoin price data to create a regression model for predicting the High price based on Volume. Unlike clustering, regression models the relationship between inputs and outputs for prediction purposes. On the other hand, clustering is an unsupervised learning method that divides unlabeled data into groups with similar characteristics. This is used to discover hidden patterns or structures within the data. Clustering is not appropriate in this context because the goal of the code is not to group data points but to solve a regression problem by predicting the value of a specific variable based on the value of another variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04088a47-d4f8-42b2-ab6f-1963caaf5b6f",
   "metadata": {},
   "source": [
    "#### Visualize and create a narrative about what you have discovered in the data. Don't just be descriptive, think predictively.\n",
    "\n",
    "- As mentioned, my data is more suited for regression analysis, and thus, I was unable to identify specific patterns through clustering. The first clustering was a graph that divided into three clusters with 'high' on the y-axis and 'volume' on the x-axis. The second clustering classified based on whether the fluctuation rate was above or below zero, and whether the volume was above or below the median, before proceeding with the clustering. Consequently, no specific patterns could be identified in either the first or second graph. In the first cluster, it was observed that the data was uniformly divided into three areas without any discernible pattern. In the second cluster, it was noted that all the clustered groups were evenly distributed across four groups. The vertical separation indicated that a significant volume of trades was concentrated at the starting point, suggesting that clustering did not reveal any unique patterns for prediction purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a3153-6e13-4c42-a60f-b684a5616b3d",
   "metadata": {},
   "source": [
    " ### Is there anomalous data? What does it mean?\n",
    "- There was an outlier present, located around 8 in volume and -20 in fluctuation rate, which stands out from the other data points. This outlier signifies a point where there was a significant drop of around -20% in fluctuation rate at a high volume of trading. While the initial hypothesis might have been that high trading volume leads to price increases, this outlier suggests the opposite.\n",
    "\n",
    "- Such outliers should be considered in data analysis, and it's important to investigate whether they are affecting the analysis results. Handling these outliers appropriately and examining their impact on the analysis findings is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37e02a-1363-4e64-9541-b98b8ac24ad0",
   "metadata": {},
   "source": [
    "### Explore more advanced regression/classifier tools.  (Random Forrest is interesting, Neural Nets are king.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb9df8-f28b-46d0-8f36-f36a42e81bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X = dataset[['Volume']] \n",
    "y = dataset['High']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = mlp.score(X_test, y_test) \n",
    "\n",
    "print(\"MSE for mlpregressor:\",mse)\n",
    "print(\"R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827b5da-1def-4202-8663-ea63171181d1",
   "metadata": {},
   "source": [
    "* MSE for mlpregressor: 123191946.24168992\n",
    "* R2: 0.4642512032187618\n",
    "* description: as the result of MSE is 123191946.24168992 it means that this MSE value indicates a relatively high error. and also r2 has 46.4% it means that the model cannot describe the correlation between volume and Hight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2102aa-9785-46d6-b3e4-c96ae869f72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48c457-65da-45b5-a888-1263f1bdf059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83182437-fc6e-493d-8ce9-3afb246c8cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
